x-base-collectors: 
  python: &python-collector
    restart: always
    depends_on:
      initializer:
        condition: service_completed_successfully
    networks:
      - kafka-clients
      - collectors
  java-cpc: &java-cpc-collector
    restart: always
    image: domrad/java-standalone
    entrypoint: [ "java", "-Dlog4j2.configurationFile=file:log4j2.xml", "-cp", "/app/domainradar-collector.jar", "cz.vut.fit.domainradar.standalone.StandaloneCollectorRunner" ]
    depends_on:
      initializer:
        condition: service_completed_successfully
    networks:
      - kafka-clients
      - collectors

services:
  kafka1:
    image: docker.io/apache/kafka:3.7.0
    hostname: kafka1
    volumes:
      - kafka1-single-log:/var/lib/kafka/data
    secrets:
      - kafka-truststore
      - kafka1-keystore
    networks:
      kafka-clients:
        ipv4_address: 192.168.100.2
        aliases: [ "kafka1" ]
      kafka-outside-world:
        ipv4_address: 192.168.103.250
    ports:
      - "31013:31013"
    env_file:
      - ./envs/kafka1_single.env

  kafka-connect:
    build:
      context: .
      dockerfile: ./dockerfiles/kafka-connect.Dockerfile
    depends_on:
      initializer:
        condition: service_completed_successfully
      postgres:
        condition: service_started
      mongo:
        condition: service_started
    secrets:
      - kafka-truststore
      - client1-keystore
    networks:
      kafka-clients:
        ipv4_address: 192.168.100.10
        aliases: [ "kafka-connect" ]
      databases: {}
      outside-world:
        ipv4_address: 192.168.103.242
    ports:
      - "31002:8083"
    volumes:
      - ./connect_properties/:/opt/kafka-connect/config/
      - kafka-connect-offsets:/tmp/kafka-connect

  kafka-ui:
    image: docker.io/provectuslabs/kafka-ui:latest
    depends_on:
      - kafka1
    secrets:
      - kafka-truststore
      - client1-keystore
    networks:
      kafka-clients:
        ipv4_address: 192.168.100.11
      outside-world:
        ipv4_address: 192.168.103.243
    ports:
      - "31000:8080"
    volumes:
      - ./client_properties/kafka_ui.yml:/etc/kafkaui/dynamic_config.yaml
    env_file:
      - ./envs/kafka_ui.env
    environment:
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka1:9093

  initializer:
    build:
      context: .  # The root of the domainradar repo
      dockerfile: ./dockerfiles/initializer.Dockerfile
    depends_on:
      - kafka1
    secrets:
      - kafka-truststore
      - client1-keystore
    networks:
      - kafka-clients
    volumes:
      - ./client_properties/initializer.properties:/scripts/client.properties
    environment:
      - BOOTSTRAP=kafka1:9093
      - COMMAND_CONFIG_FILE=/scripts/client.properties
      - EXTRA_SLEEP=0
      - UPDATE_EXISTING_TOPICS=0

  collector-zone:
    <<: *python-collector
    image: domrad/zone
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    volumes:
      - ./client_properties/zone.toml:/app/config.toml
    
  collector-dns:
    <<: *python-collector
    image: domrad/dns
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    volumes:
      - ./client_properties/dns.toml:/app/config.toml

  collector-tls:
    <<: *java-cpc-collector
    entrypoint: [ "java", "-Djava.security.properties=/app/legacy.security", "-Dlog4j2.configurationFile=file:log4j2.xml", "-cp", "/app/domainradar-collector.jar", "cz.vut.fit.domainradar.standalone.StandaloneCollectorRunner" ]
    command: [ "--col-tls", "-id", "${ID_PREFIX-domrad}", "-p", "/app/client.properties", "-s", "kafka1:9093" ]
    secrets:
      - kafka-truststore
      - client2-keystore
    volumes:
      - ./client_properties/tls.properties:/app/client.properties
      - ./client_properties/log4j2.xml:/app/log4j2.xml

  collector-nerd:
    <<: *java-cpc-collector
    command: [ "--col-nerd", "-id", "${ID_PREFIX-domrad}", "-p", "/app/client.properties", "-s", "kafka1:9093" ]
    secrets:
      - kafka-truststore
      - client2-keystore
    volumes:
      - ./client_properties/nerd.properties:/app/client.properties
      - ./client_properties/log4j2.xml:/app/log4j2.xml

  collector-geoip:
    <<: *java-cpc-collector
    command: [ "--col-geo", "-id", "${ID_PREFIX-domrad}", "-p", "/app/client.properties", "-s", "kafka1:9093" ]
    secrets:
      - kafka-truststore
      - client2-keystore
    volumes:
      - ./geoip_data/:/app/geoip/
      - ./client_properties/geoip.properties:/app/client.properties
      - ./client_properties/log4j2.xml:/app/log4j2.xml

  collector-rdap-dn:
    <<: *python-collector
    image: domrad/rdap-dn
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    volumes:
      - ./client_properties/rdap_dn.toml:/app/config.toml
    
  collector-rdap-ip:
    <<: *python-collector
    image: domrad/rdap-ip
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    volumes:
      - ./client_properties/rdap_ip.toml:/app/config.toml

  collector-rtt:
    <<: *python-collector
    image: domrad/rtt
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    volumes:
      - ./client_properties/rtt.toml:/app/config.toml
    cap_add:
      - CAP_NET_RAW
      - CAP_NET_ADMIN

  merger:
    image: domrad/java-streams
    entrypoint: [ "java", "-Dlog4j2.configurationFile=file:log4j2.xml", "-cp", "/app/domainradar-collector.jar", "cz.vut.fit.domainradar.streams.StreamsPipelineRunner" ]
    command: [ "--merger", "-id", "${ID_PREFIX-domrad}-merger", "-p", "/app/client.properties", "-s", "kafka1:9093" ]
    depends_on:
      initializer:
        condition: service_completed_successfully
    secrets:
      - kafka-truststore
      - client2-keystore
    networks:
      - kafka-clients
    volumes:
      - ./client_properties/merger.properties:/app/client.properties
      - ./client_properties/log4j2.xml:/app/log4j2.xml
      - streams-state-dir:/app/streams-state

  extractor:
    image: domrad/extractor
    depends_on:
      initializer:
        condition: service_completed_successfully
    secrets:
      - ca-cert
      - client2-cert
      - client2-key
    networks:
      - kafka-clients
    volumes:
      - ./client_properties/extractor.toml:/app/config.toml
      - ./extractor_data/:/app/data/

  # --- Databases ---

  postgres:
    image: docker.io/postgres:16
    restart: always
    secrets:
      - postgres_master_password
      - postgres_prefilter_password
      - postgres_ingestion_password
      - postgres_connect_password
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./db/postgres/init/:/docker-entrypoint-initdb.d/
      - ./db/postgres/postgres.conf:/etc/postgresql/postgresql.conf
    env_file:
      - ./db/postgres/postgres.env
    ports:
      - "31010:5432"
    networks:
      databases:
        ipv4_address: 192.168.101.2
        aliases: [ "postgres" ]
      outside-world:
        ipv4_address: 192.168.103.244

  mongo:
    image: docker.io/mongo:7
    command: --config /etc/mongod.conf
    restart: always
    secrets:
      - mongo_master_password
      - mongo_ui_password
      - mongo_connect_password
    volumes:
      - mongo-data:/data/db
      - ./db/mongo/init/:/docker-entrypoint-initdb.d/
      - ./db/mongo/mongod.conf.yml:/etc/mongod.conf
    env_file:
      - ./db/mongo/mongo.env
    ports:
      - "31011:27017"
    networks:
      databases:
        ipv4_address: 192.168.101.3
        aliases: [ "mongo" ]
      outside-world:
        ipv4_address: 192.168.103.245

  mongo-domains-refresher: &mongo-aggregation-service
    build: 
      context: .
      dockerfile: ./dockerfiles/run_aggregation.Dockerfile
    restart: always
    depends_on:
      - mongo
    secrets:
      - mongo_master_password
    networks:
      databases:
        ipv4_address: 192.168.101.20
    environment:
      - AGGREGATION=results_without_classification_history.js
      - PERIOD_SEC=60

  mongo-raw-data-refresher:
    <<: *mongo-aggregation-service
    networks:
      databases:
        ipv4_address: 192.168.101.21
    environment:
      - AGGREGATION=all_raw_data.js
      - PERIOD_SEC=600

volumes:
  kafka1-single-log: {}
  postgres-data: {}
  mongo-data: {}
  kafka-connect-offsets: {}
  streams-state-dir: {}

networks:
  kafka-clients:
    driver: bridge
    enable_ipv6: false
    internal: true
    ipam:
      config:
        - subnet: 192.168.100.0/24
          gateway: 192.168.100.1
          ip_range: 192.168.100.128/25
  databases:
    driver: bridge
    enable_ipv6: false
    internal: true
    ipam:
      config:
        - subnet: 192.168.101.0/24
          gateway: 192.168.101.1
          ip_range: 192.168.101.128/25
  collectors:
    driver: bridge
    enable_ipv6: true
    ipam:
      config:
        - subnet: 192.168.102.0/24
          gateway: 192.168.102.1
          ip_range: 192.168.102.128/25
        - subnet: fd10:3456:789a:1::/64
  outside-world:
    driver: bridge
    enable_ipv6: false
    ipam:
      config:
        - subnet: 192.168.103.240/29
          gateway: 192.168.103.241
  kafka-outside-world:
    driver: bridge
    enable_ipv6: false
    ipam:
      config:
        - subnet: 192.168.103.248/29
          gateway: 192.168.103.249

secrets:
  kafka-truststore:
    file: ./secrets/kafka.truststore.jks
  kafka1-keystore:
    file: ./secrets/secrets_kafka1/kafka1.keystore.jks
  client1-keystore:
    file: ./secrets/secrets_client1/client1.keystore.jks
  client2-keystore:
    file: ./secrets/secrets_client2/client2.keystore.jks
  ca-cert:
    file: ./secrets/ca/ca-cert
  client2-cert:
    file: ./secrets/secrets_client2/client2-cert.pem
  client2-key:
    file: ./secrets/secrets_client2/client2-priv-key.pem

  # --- Databases ---
  postgres_master_password:
    file: ./db/postgres/master.secret
  postgres_prefilter_password:
    file: ./db/postgres/prefilter.secret
  postgres_ingestion_password:
    file: ./db/postgres/ingestion.secret
  postgres_connect_password:
    file: ./db/postgres/connect.secret
  mongo_master_password:
    file: ./db/mongo/master.secret
  mongo_ui_password:
    file: ./db/mongo/ui.secret
  mongo_connect_password:
    file: ./db/mongo/connect.secret
